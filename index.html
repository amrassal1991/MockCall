<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Call Simulator Comcast SMB wave. 24</title>
  <style>
    :root {
      --bg-main: #0a0a0a;
      --bg-container: #1a1a1a;
      --bg-message-ai: #2d2d2d;
      --bg-message-user: #1a6cd0;
      --text-main: #ffffff;
      --text-secondary: #a0a0a0;
      --accent-color: #1a6cd0;
      --success-color: #10b981;
      --error-color: #ef4444;
      --quality-bg: #2d2d2d; /* Darker background for quality panel */
      --quality-border: #444;
      --quality-score-good: #10b981; /* Green for good score */
      --quality-score-bad: #ef4444; /* Red for bad score */
      --quality-score-neutral: #f59e0b; /* Amber for neutral/needs improvement */
      color-scheme: dark;  /* Tells browser this is a dark theme */
    }

    body {
      font-family: 'Segoe UI', -apple-system, BlinkMacSystemFont, sans-serif;
      background: var(--bg-main);
      color: var(--text-main);
      margin: 0;
      padding: 0;
      height: 100vh;
      display: flex;
      flex-direction: column;
    }

    .main-layout {
      flex: 1;
      max-width: 1200px; /* Increased max-width to accommodate two columns */
      margin: 1rem auto;
      width: 100%;
      display: flex;
      gap: 1rem; /* Gap between chat and quality panel */
      height: calc(100vh - 2rem);
      flex-direction: row; /* Default for desktop */
    }

    .container {
      flex: 2.5; /* Chat container takes more space */
      display: flex;
      flex-direction: column;
      position: relative;
      background: var(--bg-container);
      box-shadow: 0 2px 12px rgba(0,0,0,0.3);
      border-radius: 12px;
      backdrop-filter: blur(10px);
    }

    .quality-panel-wrapper {
      flex: 1.5; /* Quality panel wrapper takes less space */
      display: flex;
      flex-direction: column;
      gap: 1rem;
    }

    .quality-panel {
      background: var(--quality-bg);
      box-shadow: 0 2px 12px rgba(0,0,0,0.3);
      border-radius: 12px;
      padding: 1rem;
      display: flex;
      flex-direction: column;
      border: 1px solid var(--quality-border);
      flex: 2; /* Increased flex to make it bigger */
    }

    .quality-panel h2 {
      font-size: 1.3rem;
      font-weight: 600;
      color: var(--text-main);
      margin-bottom: 1rem;
      text-align: center;
    }

    .quality-feedback-content {
      flex: 1;
      overflow-y: auto;
      padding-right: 0.5rem; /* For scrollbar space */
    }

    .quality-comment {
      background: rgba(255,255,255,0.05);
      border-left: 4px solid var(--quality-score-neutral);
      padding: 0.8rem;
      border-radius: 8px;
      margin-bottom: 0.8rem;
      font-size: 0.9rem;
      line-height: 1.4;
      box-shadow: 0 1px 3px rgba(0,0,0,0.1);
      position: relative; /* For info button positioning */
    }

    .quality-comment.good { border-color: var(--quality-score-good); }
    .quality-comment.bad { border-color: var(--quality-score-bad); }

    .quality-comment strong {
      color: var(--text-main);
    }

    .quality-feedback-content::-webkit-scrollbar {
      width: 6px;
    }

    .quality-feedback-content::-webkit-scrollbar-track {
      background: var(--quality-bg);
    }

    .quality-feedback-content::-webkit-scrollbar-thumb {
      background: rgba(255,255,255,0.2);
      border-radius: 3px;
    }

    .quality-feedback-content::-webkit-scrollbar-thumb:hover {
      background: rgba(255,255,255,0.3);
    }

    /* Info button for quality feedback */
    .quality-info-btn {
        position: absolute;
        top: 0.5rem;
        right: 0.5rem;
        background: none;
        border: none;
        color: var(--text-secondary);
        font-size: 0.9rem;
        cursor: pointer;
        opacity: 0.7;
        transition: opacity 0.2s, color 0.2s;
    }
    .quality-info-btn:hover {
        opacity: 1;
        color: var(--accent-color);
    }

    @media (max-width: 768px) {
      .main-layout {
        flex-direction: column;
        height: auto;
        margin: 0.5rem;
      }
      .container, .quality-panel, .quality-panel-wrapper {
        flex: none;
        width: auto;
        margin-bottom: 1rem;
      }
      .quality-panel, .s4-progress-panel {
        height: auto; /* Allow height to adjust on mobile */
      }
    }

    .header {
      background: var(--accent-color);
      color: var(--text-main);
      padding: 1rem;
      text-align: center;
      position: sticky;
      top: 0;
      z-index: 100;
      border-top-left-radius: 12px;
      border-top-right-radius: 12px;
      backdrop-filter: blur(8px);
      border-bottom: 1px solid rgba(255,255,255,0.1);
    }

    .header h1 {
      margin: 0;
      font-size: 1.5rem;
      font-weight: 600;
      letter-spacing: -0.02em;
    }

    .chat-container {
      flex: 1;
      overflow-y: auto;
      padding: 1rem;
      background: var(--bg-container);
    }

    .messages {
      display: flex;
      flex-direction: column;
      gap: 0.8rem;
      padding-bottom: 1rem;
    }

    .message {
      max-width: 70%;
      padding: 0.8rem 1rem;
      border-radius: 1rem;
      position: relative;
      white-space: pre-wrap;
      word-wrap: break-word;
      box-shadow: 0 2px 4px rgba(0,0,0,0.2);
      animation: fadeIn 0.3s ease-in;
      font-size: 0.95rem;
      line-height: 1.5;
      transition: all 0.2s ease-out;
    }

    /* Typing indicator animation */
    .message.user:not(.sent)::after {
      content: '';
      display: inline-block;
      width: 4px;
      height: 4px;
      background: rgba(255,255,255,0.7);
      border-radius: 50%;
      margin-left: 4px;
      vertical-align: middle;
      animation: blink 1s infinite;
    }

    .message.user {
      align-self: flex-end;
      background: var(--bg-message-user);
      color: white;
      border-bottom-right-radius: 0.4rem;
      margin-left: 2rem;
    }

    .message.ai {
      align-self: flex-start;
      background: var(--bg-message-ai);
      color: var(--text-main);
      border-bottom-left-radius: 0.4rem;
      margin-right: 2rem;
      border: 1px solid rgba(255,255,255,0.1);
    }

    .message .sender-name {
        font-weight: bold;
        margin-bottom: 0.2rem;
        display: block;
        color: rgba(255,255,255,0.7);
        font-size: 0.85rem;
    }
    .message.user .sender-name {
        text-align: right;
        color: rgba(255,255,255,0.8);
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }

    /* Custom scrollbar for Webkit browsers */
    .chat-container::-webkit-scrollbar, .quality-feedback-content::-webkit-scrollbar {
      width: 8px;
    }

    .chat-container::-webkit-scrollbar-track, .quality-feedback-content::-webkit-scrollbar-track {
      background: var(--bg-container);
    }

    .chat-container::-webkit-scrollbar-thumb, .quality-feedback-content::-webkit-scrollbar-thumb {
      background: rgba(255,255,255,0.2);
      border-radius: 4px;
    }

    .chat-container::-webkit-scrollbar-thumb:hover, .quality-feedback-content::-webkit-scrollbar-thumb:hover {
      background: rgba(255,255,255,0.3);
    }

    .controls {
      padding: 1rem;
      background: var(--bg-container);
      border-top: 1px solid rgba(255,255,255,0.1);
      display: flex;
      flex-direction: column;
      gap: 0.8rem;
      border-bottom-left-radius: 12px;
      border-bottom-right-radius: 12px;
    }

    .button-group {
      display: flex;
      gap: 1rem;
      justify-content: center;
    }

    .control-button {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      padding: 0.8rem 1.2rem;
      border: none;
      border-radius: 24px;
      background: var(--accent-color);
      color: white;
      cursor: pointer;
      font-size: 1rem;
      transition: all 0.2s;
      font-weight: 500;
      box-shadow: 0 2px 4px rgba(0,0,0,0.2);
      backdrop-filter: blur(4px);
    }

    .control-button:hover:not(:disabled) {
      background: #006cbd;
    }

    .control-button:disabled {
      background: #cccccc;
      cursor: not-allowed;
      opacity: 0.7;
    }

    .control-button .button-icon {
      font-size: 1.2rem;
    }

    .record-button {
      background: #10b981;
    }

    .record-button:hover:not(:disabled) {
      background: #059669;
      transform: translateY(-1px);
    }

    .record-button.recording {
      background: #ef4444;
      animation: pulse 1.5s infinite;
    }

    .mute-button {
      background: #6b7280;
    }

    .mute-button:hover:not(:disabled) {
      background: #4b5563;
    }

    .mute-button.muted {
      background: #ef4444;
    }

    .cancel-button {
      background: #ef4444;
    }

    .cancel-button:hover:not(:disabled) {
      background: #dc2626;
      transform: translateY(-1px);
    }

    .control-button:hover:not(:disabled) {
      transform: translateY(-1px);
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }

    @keyframes pulse {
      0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.4); }
      70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
      100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
    }

    @keyframes blink {
      0%, 100% { opacity: 1; }
      50% { opacity: 0; }
    }

    .status-bar {
      background: rgba(0,0,0,0.03);
      padding: 0.5rem;
      border-radius: 12px;
      margin-top: 0.5rem;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.5rem;
    }

    .mic-button:disabled {
      background: #ccc;
      cursor: not-allowed;
    }

    .status {
      flex: 1;
      text-align: center;
      color: var(--text-secondary);
      font-size: 0.9rem;
    }

    #loader {
      display: none;
      color: var(--accent-color);
      font-size: 0.9rem;
    }

    /* Modal styles */
    .modal {
      position: fixed;
      top: 0; left: 0; right: 0; bottom: 0;
      background: rgba(0,0,0,0.7);
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 1000;
      opacity: 0;
      visibility: hidden;
      transition: opacity 0.3s ease, visibility 0.3s ease;
    }
    .modal.show {
      opacity: 1;
      visibility: visible;
    }
    .modal-content {
      background: #23272f;
      color: #fff;
      border-radius: 10px;
      padding: 2rem;
      min-width: 320px;
      max-width: 90vw;
      box-shadow: 0 4px 32px rgba(0,0,0,0.4);
      display: flex;
      flex-direction: column;
      gap: 1rem;
      position: relative; /* For close button positioning */
    }
    .modal-content label {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
      font-size: 1rem;
    }
    .modal-content input[type="text"],
    .modal-content input[type="number"],
    .modal-content select,
    .modal-content textarea {
      margin-top: 0.2rem;
      border-radius: 6px;
      border: 1px solid #444;
      background: #181c22;
      color: #fff;
      padding: 0.4rem 0.6rem;
      font-size: 1rem;
    }
    .modal-content textarea {
      resize: vertical;
    }
    .modal-actions {
      display: flex;
      gap: 1rem;
      justify-content: flex-end;
    }
    .modal-actions button {
      background: var(--accent-color);
      color: #fff;
      border: none;
      border-radius: 6px;
      padding: 0.5rem 1rem;
      font-size: 1rem;
      cursor: pointer;
      transition: background 0.2s;
    }
    .modal-actions button:hover {
      background: #0e4a8a;
    }
    .modal-close-button {
      position: absolute;
      top: 10px;
      right: 10px;
      background: none;
      border: none;
      font-size: 1.5rem;
      color: var(--text-secondary);
      cursor: pointer;
      transition: color 0.2s;
    }
    .modal-close-button:hover {
      color: var(--text-main);
    }

    /* S4 Progress Panel */
    .s4-progress-panel {
        background: var(--quality-bg);
        box-shadow: 0 2px 12px rgba(0,0,0,0.3);
        border-radius: 12px;
        padding: 1rem;
        display: flex;
        flex-direction: column;
        gap: 1rem;
        border: 1px solid var(--quality-border);
        flex: 1; /* Reduced flex to make it smaller */
    }

    .s4-progress-panel h2 {
        font-size: 1.3rem;
        font-weight: 600;
        color: var(--text-main);
        margin-bottom: 0.5rem;
        text-align: center;
    }

    .s4-phase {
        display: flex;
        align-items: center;
        gap: 0.8rem;
        padding: 0.6rem 0.8rem;
        background: rgba(255,255,255,0.05);
        border-radius: 8px;
        transition: background 0.3s ease;
    }

    .s4-phase.active {
        background: rgba(26, 108, 208, 0.2); /* Light blue for active */
        border: 1px solid var(--accent-color);
    }
    .s4-phase.completed {
        background: rgba(16, 185, 129, 0.2); /* Light green for completed */
        border: 1px solid var(--success-color);
    }

    .s4-indicator-bulb {
        width: 18px;
        height: 18px;
        border-radius: 50%;
        background-color: #555; /* Default grey */
        box-shadow: 0 0 5px rgba(0,0,0,0.5);
        transition: background-color 0.3s ease, box-shadow 0.3s ease;
    }

    .s4-phase.active .s4-indicator-bulb {
        background-color: var(--accent-color); /* Neon blue */
        box-shadow: 0 0 8px var(--accent-color), 0 0 15px var(--accent-color);
    }
    .s4-phase.completed .s4-indicator-bulb {
        background-color: var(--success-color); /* Neon green */
        box-shadow: 0 0 8px var(--success-color), 0 0 15px var(--success-color);
    }

    .s4-phase-content {
        flex: 1;
    }

    .s4-phase-title {
        font-weight: 600;
        color: var(--text-main);
        font-size: 1rem;
    }

    .s4-phase-description {
        font-size: 0.85rem;
        color: var(--text-secondary);
        margin-top: 0.2rem;
    }
  </style>
</head>
<body>
  <div class="main-layout">
    <!-- Quality and S4 panel wrapper - now on the left -->
    <div class="quality-panel-wrapper">
      <div class="quality-panel">
        <h2>Quality Feedback</h2>
        <div class="quality-feedback-content" id="quality-feedback-panel">
          <div class="quality-comment">Feedback will appear here after each of your responses.</div>
        </div>
      </div>
      <div class="s4-progress-panel">
        <h2>S4 Progress</h2>
        <div id="s4-phases-container">
          <div class="s4-phase" id="s1-phase">
            <div class="s4-indicator-bulb"></div>
            <div class="s4-phase-content">
              <div class="s4-phase-title">S1: Start</div>
              <div class="s4-phase-description">Greeting, Reflect Reason, Empathize, Take Ownership, Authenticate/Set Agenda.</div>
            </div>
          </div>
          <div class="s4-phase" id="s2-phase">
            <div class="s4-indicator-bulb"></div>
            <div class="s4-phase-content">
              <div class="s4-phase-title">S2: Solve</div>
              <div class="s4-phase-description">Obtain Info/Probe, Resolve Issue, Build Value/Promote.</div>
            </div>
          </div>
          <div class="s4-phase" id="s3-phase">
            <div class="s4-indicator-bulb"></div>
            <div class="s4-phase-content">
              <div class="s4-phase-title">S3: Sell</div>
              <div class="s4-phase-description">Transition to Offer, Present Offer, Overcome Objections, Proactively Close Sale.</div>
            </div>
          </div>
          <div class="s4-phase" id="s4-phase">
            <div class="s4-indicator-bulb"></div>
            <div class="s4-phase-content">
              <div class="s4-phase-title">S4: Summarize</div>
              <div class="s4-phase-description">Summarize Actions, Close Contact, Documentation.</div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="header">
        <h1>Call Simulator üéß</h1>
      </div>
      <div class="chat-container" id="chat">
        <div class="messages">
          <!-- Initial message will be added by startNewRolePlay() -->
        </div>
      </div>
      <div class="controls">
        <div class="button-group">
          <button class="control-button record-button" id="mic-btn" title="Start/Stop recording">
            <span class="button-icon">üé§</span>
            <span class="button-text">Hold to Talk</span>
          </button>
          <button class="control-button mute-button" id="mute-btn" title="Mute/Unmute microphone">
            <span class="button-icon">üîä</span>
            <span class="button-text">Mute</span>
          </button>
          <button class="control-button send-button" id="send-btn" disabled title="Send message">
            <span class="button-icon">üì§</span>
            <span class="button-text">Send</span>
          </button>
          <button class="control-button cancel-button" id="cancel-btn" disabled title="Cancel recording">
            <span class="button-icon">‚ùå</span>
            <span class="button-text">Cancel</span>
          </button>
          <button class="control-button" id="save-call-btn" title="Save current call">
            <span class="button-icon">üíæ</span>
            <span class="button-text">Save Call</span>
          </button>
        </div>
        <div class="status-bar">
          <div class="status" id="status">Click microphone to start</div>
          <div id="loader">‚è≥ Processing...</div>
        </div>
      </div>

      <!-- Modal open buttons (positioned absolutely within the main container) -->
      <div class="modal-buttons" style="position:absolute;top:1rem;right:1rem;z-index:200;">
        <button id="open-settings" class="control-button" style="background: #4b5563; padding: 0.5rem; border-radius: 50%; width: 40px; height: 40px; display: flex; align-items: center; justify-content: center;" title="Settings">‚öôÔ∏è</button>
        <button id="open-persona" class="control-button" style="background: #4b5563; padding: 0.5rem; border-radius: 50%; width: 40px; height: 40px; display: flex; align-items: center; justify-content: center; margin-left: 0.5rem;" title="Persona">üßë‚Äçüíº</button>
      </div>
    </div>
  </div>

  <!-- Generic Modal Structure -->
  <div id="genericModal" class="modal">
    <div class="modal-content">
      <button class="modal-close-button" id="closeModalBtn">&times;</button>
      <h3 id="modalTitle" style="font-size: 1.2rem; font-weight: 600; margin-bottom: 1rem;"></h3>
      <div id="modalBody"></div>
      <div class="modal-actions">
        <button id="modalSaveBtn">Save</button>
        <button id="modalCancelBtn">Cancel</button>
      </div>
    </div>
  </div>

  <!-- Include Firebase SDKs -->
  <script type="module">
    import { initializeApp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-app.js";
    import { getAuth, signInAnonymously, signInWithCustomToken, onAuthStateChanged } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-auth.js";
    import { getFirestore, collection, addDoc, serverTimestamp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-firestore.js";

    // Global Firebase variables
    let app;
    let db;
    let auth;
    let userId = 'anonymous'; // Default to anonymous

    // Access global variables provided by the Canvas environment
    const appId = typeof __app_id !== 'undefined' ? __app_id : 'default-app-id';
    const firebaseConfig = typeof __firebase_config !== 'undefined' ? JSON.parse(__firebase_config) : null;
    const initialAuthToken = typeof __initial_auth_token !== 'undefined' ? __initial_auth_token : null; // Corrected initialization

    // Initialize Firebase and authenticate
    if (firebaseConfig) {
        app = initializeApp(firebaseConfig);
        db = getFirestore(app);
        auth = getAuth(app);

        onAuthStateChanged(auth, async (user) => {
            if (user) {
                userId = user.uid;
                console.log("Firebase authenticated. User ID:", userId);
            } else {
                console.log("Firebase not authenticated. Attempting anonymous sign-in.");
                try {
                    if (initialAuthToken) {
                        await signInWithCustomToken(auth, initialAuthToken);
                        userId = auth.currentUser.uid;
                        console.log("Signed in with custom token. User ID:", userId);
                    } else {
                        await signInAnonymously(auth);
                        userId = auth.currentUser.uid;
                        console.log("Signed in anonymously. User ID:", userId);
                    }
                } catch (error) {
                    console.error("Firebase authentication failed:", error);
                    // Fallback to a random UUID if anonymous sign-in fails (e.g., no internet)
                    userId = crypto.randomUUID();
                    console.warn("Using a random UUID as userId due to authentication failure:", userId);
                }
            }
        });
    } else {
        console.warn("Firebase config not found. Call saving will not be available.");
        userId = crypto.randomUUID(); // Generate a random ID if Firebase isn't configured
        document.getElementById('save-call-btn').disabled = true;
    }

    // Make Firebase instances and userId available to the global scope
    window.firebaseApp = app;
    window.firebaseDb = db;
    window.firebaseAuth = auth;
    window.currentUserId = userId; // This will be updated by onAuthStateChanged
    window.getUserId = () => userId; // Provide a getter for the current userId

    // Expose Firestore FieldValue for serverTimestamp
    window.firebase = {
        firestore: {
            FieldValue: {
                serverTimestamp: serverTimestamp
            }
        }
    };
  </script>

  <!-- Include complains.js BEFORE the main script -->
  <script src="complaints.js"></script>

  <script>
    // SpeechService Class (from previous 'both.txt' content)
    class SpeechService {
        constructor() {
            this.synthesis = window.speechSynthesis;
            this.voices = [];
            this.isSpeaking = false;
            this.volume = 0.8; // Default volume, can be updated via setVolume
            
            if (this.synthesis) {
                this.synthesis.onvoiceschanged = () => {
                    this.voices = this.synthesis.getVoices();
                    console.log('Voices loaded:', this.voices.length);
                };
                this.voices = this.synthesis.getVoices(); // Try to load immediately
            }
        }

        setVolume(volume) {
            this.volume = volume;
            console.log('SpeechService volume set to:', this.volume);
        }

        getPreferredVoice(gender = null) {
            const voices = this.voices.filter(voice => voice.lang.includes('en-US'));
            let preferredVoice = null;

            if (gender === 'male') {
                preferredVoice = voices.find(voice => voice.name.includes('Male') || voice.name.includes('David'));
            } else if (gender === 'female') {
                preferredVoice = voices.find(voice => voice.name.includes('Zira') || voice.name.includes('Samantha') || voice.name.includes('Female'));
            }
            
            return preferredVoice || voices[0] || null; // Fallback to first English voice, then null
        }

        async speak(text, gender = null) {
            return new Promise((resolve, reject) => {
                if (!this.synthesis || !text) {
                    console.log('Speech synthesis skipped: not available or no text provided.');
                    return resolve();
                }

                this.synthesis.cancel(); // Cancel any ongoing speech

                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'en-US';
                utterance.volume = this.volume;
                
                const voice = this.getPreferredVoice(gender);
                if (voice) {
                    utterance.voice = voice;
                    console.log('Using voice:', voice.name, 'for gender:', gender);
                } else {
                    console.warn('No suitable voice found for gender:', gender, '. Using default if available.');
                    if (this.voices.length > 0) {
                        utterance.voice = this.voices.find(v => v.lang.includes('en-US')) || this.voices[0];
                    } else {
                        console.error('No speech synthesis voices available. Ensure voices are installed on your OS.');
                        return resolve(); // Resolve if no voices at all
                    }
                }

                utterance.pitch = 1.0;
                utterance.rate = 0.9;

                this.isSpeaking = true;

                utterance.onend = () => {
                    console.log('Speech ended');
                    this.isSpeaking = false;
                    // Automatically reactivate microphone if not muted
                    if (!isMuted) {
                        startRecognition();
                    }
                    resolve();
                };

                utterance.onerror = (err) => {
                    console.error('Speech error:', err);
                    this.isSpeaking = false;
                    // Automatically reactivate microphone if not muted
                    if (!isMuted) {
                        startRecognition();
                    }
                    reject(err);
                };

                // Small delay to ensure synthesis is ready
                setTimeout(() => {
                    try {
                        this.synthesis.speak(utterance);
                        console.log('Speech synthesis started for:', text);
                        // Mute microphone while AI is speaking
                        stopRecognition(); 
                    } catch (e) {
                        console.error('Error calling speechSynthesis.speak():', e);
                        this.isSpeaking = false;
                        reject(e);
                    }
                }, 100);
            });
        }

        stop() {
            if (this.synthesis) {
                this.synthesis.cancel();
                this.isSpeaking = false;
                console.log('Speech synthesis stopped.');
            }
        }
    }

    const speechService = new SpeechService(); // Instantiate the SpeechService

    // Use the provided API key directly
    const API_KEY = "AIzaSyAuGsOgCCzlSBvpcelKWcZXBf1FXFx-zMg"; // Changed to empty string as per user request
    const GEMINI_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${API_KEY}`;
    
    const micBtn = document.getElementById('mic-btn');
    const sendBtn = document.getElementById('send-btn');
    const cancelBtn = document.getElementById('cancel-btn');
    const chat = document.getElementById('chat');
    const status = document.getElementById('status');
    const loader = document.getElementById('loader');
    const muteBtn = document.getElementById('mute-btn');
    const qualityFeedbackPanel = document.getElementById('quality-feedback-panel');
    const saveCallBtn = document.getElementById('save-call-btn'); // New save button

    // S4 Progress elements
    const s1Phase = document.getElementById('s1-phase');
    const s2Phase = document.getElementById('s2-phase');
    const s3Phase = document.getElementById('s3-phase');
    const s4Phase = document.getElementById('s4-phase');
    const s4Phases = {
        'S1': s1Phase,
        'S2': s2Phase,
        'S3': s3Phase,
        'S4': s4Phase
    };

    // Modal elements
    const genericModal = document.getElementById('genericModal');
    const modalTitle = document.getElementById('modalTitle');
    const modalBody = document.getElementById('modalBody');
    const closeModalBtn = document.getElementById('closeModalBtn');
    const modalSaveBtn = document.getElementById('modalSaveBtn'); // Corrected assignment
    const modalCancelBtn = document.getElementById('modalCancelBtn');

    let recognition;
    let isRecognizing = false;
    let currentTranscript = '';
    let silenceTimer = null;
    let isMuted = false;
    let autoSendDelay = 60000; // Default auto-send delay in milliseconds (60 seconds)
    let lastSpeechEndTime = 0; // To track dead air

    // Chat history for context
    let chatHistory = []; // This will store alternating user (agent) and model (customer AI) turns
    let qualityFeedbackHistory = []; // Stores structured quality feedback

    // Initial customer scenario setup - now dynamically set
    let currentScenario = null; // Stores the full scenario object
    let currentInitialCustomerScenarioText = ""; // Stores just the initial complaint text
    let currentS4Phase = 'S1'; // Track current S4 phase

    let customerPersona = "You are a Comcast customer with a billing inquiry. You are slightly frustrated but polite. Respond concisely. Ensure your responses have variance and do not sound robotic.";
    let qualityAssistantPersona = "You are an S4 Quality Assurance Specialist. Evaluate the agent's last response based on the S4 guidelines provided. Provide a score out of 100 and a brief comment. Focus on Start, Solve, Sell, Summarize, and Foundational Behaviors. Also, identify the current S4 phase (S1, S2, S3, or S4) the conversation is in based on the agent's last response and the overall flow.";
    let flowManagerPersona = "You are a Call Flow Manager AI. Your role is to guide the agent through the S4 call flow. Based on the conversation history and the current S4 phase, provide a subtle suggestion or prompt to help the agent progress or conclude the call. Your tone should be helpful and encouraging, not critical. Suggest the next logical S4 phase or a concluding action (e.g., 'summarize the call').";


    const S4_GUIDELINES_SUMMARY = `
        S4 Universal Call Flow:
        - S1: Start (Greeting, Reflect Reason, Relate/Empathize, Take Ownership, Authenticate/Set Agenda)
        - S2: Solve (Obtain Info/Probe, Resolve Issue, Build Value/Promote)
        - S3: Sell (Transition to Offer, Present Offer, Overcome Objections, Proactively Close Sale)
        - S4: Summarize (Summarize Actions, Close Contact, Documentation)
        Foundational Behaviors: Tone, Confidence, Clarity; Active Listening; Contact Management; Acknowledge/Take Responsibility; Build Rapport/Demonstrate Concern.
        Scoring: Highly Effective (HE) gives more points than Meets Expectations (ME). Below Expectations (BE) gives 0 points.
        Critical Failures: Auto-Fail (e.g., Rudeness, Inappropriate Transfer) results in 0 overall. Section Failure (e.g., Authentication failure) results in 0 for that section.
    `;

    function addMessage(text, sender, senderName = '') {
      const messages = chat.querySelector('.messages');
      const div = document.createElement('div');
      div.className = `message ${sender}`;
      if (senderName) {
          const nameSpan = document.createElement('span');
          nameSpan.className = 'sender-name';
          nameSpan.textContent = senderName;
          div.appendChild(nameSpan);
      }
      const textNode = document.createTextNode(text);
      div.appendChild(textNode);
      messages.appendChild(div);
      chat.scrollTop = messages.scrollHeight; // Use messages.scrollHeight for more reliable scroll
    }

    function addQualityFeedback(score, comment, details = {}) {
      const div = document.createElement('div');
      div.classList.add('quality-comment');
      if (score >= 80) {
        div.classList.add('good');
      } else if (score < 60) {
        div.classList.add('bad');
      }
      div.innerHTML = `<strong>Score: ${score}/100</strong><br>${comment}`;
      
      const infoBtn = document.createElement('button');
      infoBtn.className = 'quality-info-btn';
      infoBtn.innerHTML = 'üí°';
      infoBtn.title = 'Click for more details';
      infoBtn.onclick = () => showQualityDetails(details);
      div.appendChild(infoBtn);

      qualityFeedbackPanel.appendChild(div);
      qualityFeedbackPanel.scrollTop = qualityFeedbackPanel.scrollHeight;
      qualityFeedbackHistory.push({ score, comment, details }); // Store structured feedback with details
    }

    function showQualityDetails(details) {
        let detailHtml = `<h4>Feedback Details:</h4>`;
        if (details.s4Phase) {
            detailHtml += `<p><strong>S4 Phase:</strong> ${details.s4Phase}</p>`;
        }
        if (details.confidence !== undefined) {
            detailHtml += `<p><strong>Speech Confidence:</strong> ${(details.confidence * 100).toFixed(1)}%</p>`;
        }
        if (details.deadAirDuration !== undefined) {
            detailHtml += `<p><strong>Dead Air Duration:</strong> ${details.deadAirDuration.toFixed(1)} seconds</p>`;
        }
        if (details.reasoning) {
            detailHtml += `<p><strong>AI Reasoning:</strong> ${details.reasoning}</p>`;
        }
        if (details.suggestions) {
            detailHtml += `<p><strong>Suggestions:</strong> ${details.suggestions}</p>`;
        }
        // Add more details as needed
        showModal('Quality Feedback Details', detailHtml, null, true); // Pass true to hide save/cancel buttons
    }

    function updateStatus(message, showLoader = false) {
      status.textContent = message;
      loader.style.display = showLoader ? 'inline-block' : 'none';
      micBtn.disabled = showLoader;
      sendBtn.disabled = showLoader;
      cancelBtn.disabled = showLoader;
      // Mute button should always be active for manual toggle
      // muteBtn.disabled = showLoader; // Keep mute button active
    }

    function initRecognition() {
      const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SR) {
        addMessage('Speech recognition not supported in this browser. Please use Chrome for best experience.', 'ai');
        micBtn.disabled = true;
        return null;
      }

      const rec = new SR();
      rec.lang = 'en-US';
      rec.continuous = false;
      rec.interimResults = true;

      rec.onstart = () => {
        isRecognizing = true;
        micBtn.classList.add('recording');
        sendBtn.disabled = true;
        cancelBtn.disabled = false;
        updateStatus('Listening...');
        currentTranscript = '';
        clearTimeout(silenceTimer);
        lastSpeechEndTime = performance.now(); // Reset dead air timer
      };

      let lastTranscript = '';
      rec.onresult = (e) => {
        clearTimeout(silenceTimer); // Reset silence timer on any speech
        
        let interimTranscript = '';
        let finalTranscript = '';
        let confidence = 0;
        
        for (let i = 0; i < e.results.length; i++) {
          const transcript = e.results[i][0].transcript;
          if (e.results[i].isFinal) {
            finalTranscript = transcript;
            confidence = e.results[i][0].confidence;
          } else {
            interimTranscript = transcript;
          }
        }

        const fullTranscript = (finalTranscript || interimTranscript).trim();
        
        if (fullTranscript !== lastTranscript) {
          const newWords = fullTranscript.slice(lastTranscript.length).trim();
          
          const command = newWords.toLowerCase();
          if (command === 'send' || command.endsWith(' send')) {
            if (currentTranscript.trim()) {
              sendMessage(currentTranscript.trim(), confidence); // Pass confidence
            }
            return;
          } else if (command === 'delete' || command.endsWith(' delete')) {
            currentTranscript = '';
            const messages = chat.querySelector('.messages').lastElementChild;
            if (messages && messages.classList.contains('user') && !messages.classList.contains('sent')) {
              messages.remove();
            }
            return;
          }

          currentTranscript = fullTranscript;
          lastTranscript = fullTranscript;
          lastSpeechEndTime = performance.now(); // Update last speech time

          sendBtn.disabled = !currentTranscript;

          let messageElement = chat.querySelector('.messages').lastElementChild;
          if (messageElement && messageElement.classList.contains('user') && !messageElement.classList.contains('sent')) {
            messageElement.textContent = currentTranscript;
          } else {
            messageElement = document.createElement('div');
            messageElement.className = 'message user';
            messageElement.innerHTML = `<span class="sender-name">Agent:</span>${currentTranscript}`; // Add sender name
            chat.querySelector('.messages').appendChild(messageElement);
          }
          chat.scrollTop = chat.scrollHeight;
        }

        // Start new silence timer only if currently recognizing and there's a transcript
        if (isRecognizing && currentTranscript.trim()) {
            silenceTimer = setTimeout(() => {
                console.log('Silence detected - auto-sending message');
                const deadAirDuration = (performance.now() - lastSpeechEndTime) / 1000;
                sendMessage(currentTranscript.trim(), confidence, deadAirDuration); // Pass confidence and dead air
            }, autoSendDelay); // Use autoSendDelay
        }
      };

      rec.onerror = (e) => {
        console.error('Speech recognition error:', e.error);
        if (e.error === 'network') {
          updateStatus('Network error. Retrying...', true);
          setTimeout(() => {
            if (isRecognizing) startRecognition();
          }, 1000);
        } else if (e.error === 'not-allowed') {
            updateStatus('Microphone access denied. Please enable microphone permissions in your browser settings. Then, refresh the page.', false);
            micBtn.disabled = true; // Disable mic button if permission is denied
        }
        else {
          updateStatus(`Error: ${e.error}`);
          stopRecognition();
        }
      };

      rec.onend = () => {
        isRecognizing = false;
        micBtn.classList.remove('recording');
        cancelBtn.disabled = true;
        // Only update status if not already showing a permission error
        if (status.textContent !== 'Microphone access denied. Please enable microphone permissions in your browser settings. Then, refresh the page.') {
            updateStatus('Click mic to start');
        }
        clearTimeout(silenceTimer); // Ensure timer is cleared on end
        recognition = null; // Reset recognition object to force re-initialization on next start
      };

      return rec;
    }

    function startRecognition() {
      if (isMuted || speechService.isSpeaking) { // Don't start if muted or AI is speaking
        console.log('Recognition blocked: muted or AI is speaking.');
        return;
      }
      if (!recognition) {
        recognition = initRecognition();
        if (!recognition) return; // If initRecognition failed, stop here
      }

      try {
        recognition.start();
        console.log('Recognition started.');
      } catch (e) {
        console.error('Failed to start recognition:', e);
        updateStatus('Failed to access microphone. Please check permissions.');
      }
    }

    function stopRecognition() {
      if (recognition && isRecognizing) {
        recognition.stop();
        console.log('Recognition stopped.');
        clearTimeout(silenceTimer);
      }
    }

    function toggleMute() {
      isMuted = !isMuted;
      muteBtn.classList.toggle('muted');
      muteBtn.querySelector('.button-icon').textContent = isMuted ? 'üîá' : 'üîä';
      muteBtn.querySelector('.button-text').textContent = isMuted ? 'Unmute' : 'Mute';
      
      if (isMuted) {
        stopRecognition(); // Stop recognition immediately if muted
        speechService.stop(); // Stop any ongoing speech
        console.log('Microphone manually muted.');
      } else {
        // If unmuted and AI is not speaking, restart recognition
        if (!speechService.isSpeaking) {
          startRecognition();
          console.log('Microphone manually unmuted.');
        }
      }
    }

    async function sendMessage(text, confidence = 0, deadAirDuration = 0) {
      if (!text.trim()) return;
      
      clearTimeout(silenceTimer);
      stopRecognition(); // Ensure recognition is stopped before sending

      // Mark the last user message as sent
      const messages = chat.querySelector('.messages').lastElementChild;
      if (messages && messages.classList.contains('user') && !messages.classList.contains('sent')) {
        messages.classList.add('sent');
      } else {
        // If message was auto-sent without interim display, add it now
        addMessage(text, 'user', 'Agent:'); // Add sender name
        chat.querySelector('.messages').lastElementChild.classList.add('sent');
      }

      const wasMuted = isMuted;
      isMuted = true; // Temporarily mute during AI processing
      muteBtn.classList.add('muted');
      muteBtn.querySelector('.button-icon').textContent = 'üîá';
      
      updateStatus('Processing...', true);

      try {
        // --- Role-Play AI (Customer Response) ---
        // Construct customer payload with persona and initial complaint as system/user context
        const customerPrompt = `As the customer, respond to the agent's last message.
        Customer Persona: ${customerPersona}
        Initial Complaint: "${currentInitialCustomerScenarioText}"
        Conversation History: ${JSON.stringify(chatHistory.slice(-6))}
        Agent's Last Message: "${text}"
        Your response:`;

        const customerPayload = { contents: [{ role: "user", parts: [{ text: customerPrompt }] }] };
        console.log("Customer AI Request Payload:", JSON.stringify(customerPayload, null, 2));

        const customerRes = await fetch(GEMINI_API_URL, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(customerPayload)
        });
        const customerData = await customerRes.json();
        console.log("Customer AI Raw Response:", JSON.stringify(customerData, null, 2)); // Log raw response

        let customerReply = '(No customer response)';
        if (customerData.candidates && customerData.candidates.length > 0 &&
            customerData.candidates[0].content && customerData.candidates[0].content.parts &&
            customerData.candidates[0].content.parts.length > 0) {
            customerReply = customerData.candidates[0].content.parts[0].text;
        } else {
            console.error("Customer AI did not return a valid response structure or content:", customerData);
            customerReply = '(Customer AI did not generate a valid response)';
        }
        
        addMessage(customerReply, 'ai', `${currentScenario.customerName}:`); // Add customer name
        chatHistory.push({ role: "user", parts: [{ text: text }] }); // Add agent's message to history
        chatHistory.push({ role: "model", parts: [{ text: customerReply }] }); // Add customer's response to history

        if (!wasMuted) { // Speak only if not originally muted
          await speechService.speak(customerReply, currentScenario.customerGender); // Use speechService instance with gender
        }

        // --- Quality AI Analysis ---
        let precedingCustomerMessageText = '';
        // Find the most recent 'model' message before the current agent's message in chatHistory
        for (let i = chatHistory.length - 1; i >= 0; i--) {
            if (chatHistory[i].role === 'model') {
                precedingCustomerMessageText = chatHistory[i].parts[0].text;
                break;
            }
        }
        
        const qualityPrompt = `As an S4 Quality Assurance Specialist, evaluate the agent's response based on the S4 guidelines. Provide a score out of 100, a brief comment, the current S4 phase (S1, S2, S3, or S4) the conversation is in, your reasoning for the score, and suggestions for improvement or better wordings.
        S4 Guidelines Summary: ${S4_GUIDELINES_SUMMARY}
        
        Here is the conversation turn to evaluate:
        Customer: "${precedingCustomerMessageText || currentInitialCustomerScenarioText}"
        Agent: "${text}"
        
        Focus specifically on whether the agent's response was appropriate given the customer's statement *immediately preceding* the agent's response (or the initial scenario if this is the first agent response).
        For the 'Start' phase (S1), ensure the agent reflects the reason for contact and shows empathy *if the reason was provided by the customer*. If no specific reason was explicitly provided yet by the customer, evaluate the general greeting and rapport building.
        Consider the overall flow and adherence to S4 principles.
        Also consider the agent's speech characteristics:
        - Speech Confidence: ${(confidence * 100).toFixed(1)}% (Higher is better)
        - Dead Air Duration: ${deadAirDuration.toFixed(1)} seconds (Lower is better, typically aim for < 1 second within a turn, but longer pauses between turns are natural)
        
        Provide your response in JSON format with the following keys: "score" (integer), "comment" (string), "s4Phase" (string, e.g., "S1", "S2", "S3", "S4" - YOU MUST PROVIDE ONE OF THESE), "reasoning" (string), "suggestions" (string).`;
            
        const qualityResponseSchema = {
            type: "OBJECT",
            properties: {
                "score": { "type": "INTEGER" },
                "comment": { "type": "STRING" },
                "s4Phase": { "type": "STRING", "enum": ["S1", "S2", "S3", "S4"] },
                "reasoning": { "type": "STRING" },
                "suggestions": { "type": "STRING" }
            },
            "propertyOrdering": ["score", "comment", "s4Phase", "reasoning", "suggestions"]
        };

        const qualityPayload = { 
            contents: [{ role: "user", parts: [{ text: qualityPrompt }] }],
            generationConfig: {
                responseMimeType: "application/json",
                responseSchema: qualityResponseSchema
            }
        };
        console.log("Quality AI Request Payload:", JSON.stringify(qualityPayload, null, 2));

        const qualityRes = await fetch(GEMINI_API_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(qualityPayload)
        });
        const qualityData = await qualityRes.json();
        console.log("Quality AI Raw Response:", JSON.stringify(qualityData, null, 2)); // Log raw response
        let qualityFeedback = { score: 0, comment: 'Error: Could not get quality feedback.', s4Phase: 'S1', reasoning: 'No reasoning provided.', suggestions: 'No suggestions provided.' }; // Default to S1
        let qualityDetails = { confidence, deadAirDuration };

        if (qualityData.candidates && qualityData.candidates.length > 0 &&
            qualityData.candidates[0].content && qualityData.candidates[0].content.parts &&
            qualityData.candidates[0].content.parts.length > 0) {
            try {
                const jsonText = qualityData.candidates[0].content.parts[0].text;
                const parsedFeedback = JSON.parse(jsonText);
                qualityFeedback = { ...qualityFeedback, ...parsedFeedback }; // Merge parsed data
                qualityDetails = { ...qualityDetails, ...parsedFeedback }; // Add AI's reasoning/suggestions to details
            } catch (parseError) {
                console.error('Error parsing quality AI JSON:', parseError);
                qualityFeedback.comment = `Error parsing quality feedback: ${parseError.message}`;
                qualityDetails.reasoning = `Error parsing quality feedback: ${parseError.message}`;
            }
        } else {
            console.error('Quality AI returned an unexpected structure:', qualityData);
            qualityFeedback.comment = 'Error: Unexpected quality AI response structure.';
            qualityDetails.reasoning = 'Unexpected quality AI response structure.';
        }
        
        addQualityFeedback(qualityFeedback.score, qualityFeedback.comment, qualityDetails);
        currentS4Phase = qualityFeedback.s4Phase; // Update current S4 phase based on quality AI
        console.log("Quality AI returned S4 Phase:", currentS4Phase); // Log the phase returned by quality AI
        updateS4Progress(currentS4Phase);

        // --- Flow Management AI ---
        const flowManagerPrompt = `As a Call Flow Manager AI, your role is to guide the agent through the S4 call flow.
        Current S4 Phase: ${currentS4Phase}.
        Conversation History: ${JSON.stringify(chatHistory.slice(-4))} (last 4 turns for context)
        Agent's Last Response: "${text}"
        Customer's Last Response: "${customerReply}"

        Based on the current S4 phase and the recent conversation, provide a subtle suggestion or prompt to help the agent progress or conclude the call. Your tone should be helpful and encouraging, not critical.
        
        If the current phase is S1, suggest moving towards problem-solving.
        If the current phase is S2, suggest looking for sales opportunities or resolving the issue fully.
        If the current phase is S3, suggest closing the sale or moving to summarization if the sale is not viable.
        If the current phase is S4, suggest concluding the call.
        If the conversation seems stuck or repetitive, suggest a way to move forward.

        Provide your response in JSON format with the following keys: "suggestion" (string), "nextS4Phase" (string, e.g., "S1", "S2", "S3", "S4", "Completed"), "interventionNeeded" (boolean, true if a strong prompt is needed).`;

        const flowManagerResponseSchema = {
            type: "OBJECT",
            properties: {
                "suggestion": { "type": "STRING" },
                "nextS4Phase": { "type": "STRING", "enum": ["S1", "S2", "S3", "S4", "Completed"] },
                "interventionNeeded": { "type": "BOOLEAN" }
            },
            "propertyOrdering": ["suggestion", "nextS4Phase", "interventionNeeded"]
        };

        const flowManagerPayload = {
            contents: [{ role: "user", parts: [{ text: flowManagerPrompt }] }],
            generationConfig: {
                responseMimeType: "application/json",
                responseSchema: flowManagerResponseSchema
            }
        };
        console.log("Flow Manager AI Request Payload:", JSON.stringify(flowManagerPayload, null, 2));

        const flowManagerRes = await fetch(GEMINI_API_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(flowManagerPayload)
        });
        const flowManagerData = await flowManagerRes.json();
        console.log("Flow Manager AI Raw Response:", JSON.stringify(flowManagerData, null, 2)); // Log raw response
        let flowManagerFeedback = { suggestion: '', nextS4Phase: currentS4Phase, interventionNeeded: false };

        if (flowManagerData.candidates && flowManagerData.candidates.length > 0 &&
            flowManagerData.candidates[0].content && flowManagerData.candidates[0].content.parts &&
            flowManagerData.candidates[0].content.parts.length > 0) {
            try {
                const jsonText = flowManagerData.candidates[0].content.parts[0].text;
                flowManagerFeedback = JSON.parse(jsonText);
            } catch (parseError) {
                console.error('Error parsing flow manager AI JSON:', parseError);
            }
        }

        if (flowManagerFeedback.suggestion) {
            addMessage(flowManagerFeedback.suggestion, 'ai', 'Flow Manager:');
        }
        if (flowManagerFeedback.nextS4Phase && flowManagerFeedback.nextS4Phase !== currentS4Phase) {
            // Optionally update S4 progress based on Flow Manager's suggestion if it's a clear progression
            // For now, we'll let Quality AI drive the main S4 progress, but this could be an override.
        }


      } catch (e) {
        console.error('API Error:', e);
        addMessage('Sorry, I encountered an error processing your message.', 'ai', `${currentScenario.customerName}:`);
        addQualityFeedback(0, `API Error: ${e.message}`, { confidence, deadAirDuration, reasoning: `API Error: ${e.message}`, suggestions: 'Check network connection or API key.' });
      } finally {
        updateStatus('Click mic to start', false);
        currentTranscript = '';
        // Restore previous mute state and restart recognition if not muted and AI is not speaking
        if (!wasMuted && !speechService.isSpeaking) {
          isMuted = false;
          muteBtn.classList.remove('muted');
          muteBtn.querySelector('.button-icon').textContent = 'üîä';
          startRecognition();
        }
      }
    }

    micBtn.addEventListener('click', () => {
      if (isRecognizing) {
        stopRecognition();
      } else {
        startRecognition();
      }
    });

    sendBtn.addEventListener('click', () => {
      if (currentTranscript.trim()) {
        const confidence = recognition && recognition.currentResult ? recognition.currentResult[0].confidence : 0;
        const deadAirDuration = (performance.now() - lastSpeechEndTime) / 1000;
        sendMessage(currentTranscript.trim(), confidence, deadAirDuration);
      }
    });

    cancelBtn.addEventListener('click', () => {
      currentTranscript = '';
      const messages = chat.querySelector('.messages').lastElementChild;
      if (messages && messages.classList.contains('user') && !messages.classList.contains('sent')) {
        messages.remove();
      }
      stopRecognition();
      updateStatus('Click mic to start', false);
      sendBtn.disabled = true;
    });

    muteBtn.addEventListener('click', toggleMute);

    // --- Modal Functions ---
    function showModal(title, bodyHtml, onSaveCallback, hideActionButtons = false) {
        modalTitle.textContent = title;
        modalBody.innerHTML = bodyHtml;
        genericModal.classList.add('show');

        modalSaveBtn.style.display = hideActionButtons ? 'none' : 'inline-block';
        modalCancelBtn.style.display = hideActionButtons ? 'none' : 'inline-block';

        modalSaveBtn.onclick = null; 
        if (onSaveCallback) {
            modalSaveBtn.onclick = onSaveCallback;
        }
    }

    function hideModal() {
        genericModal.classList.remove('show');
    }

    closeModalBtn.addEventListener('click', hideModal);
    modalCancelBtn.addEventListener('click', hideModal);
    // modalSaveBtn event listener is now set dynamically in showModal

    document.getElementById('open-settings').addEventListener('click', () => {
        let scenarioOptionsHtml = '';
        const allScenarios = [];
        for (const category in window.complaints) {
            window.complaints[category].forEach(scenario => {
                allScenarios.push(scenario);
            });
        }

        // Create options for the dropdown
        for (const category in window.complaints) {
            scenarioOptionsHtml += `<optgroup label="${category.charAt(0).toUpperCase() + category.slice(1)}">`;
            window.complaints[category].forEach(scenario => {
                const selected = (scenario === currentScenario) ? 'selected' : ''; // Compare full scenario object
                scenarioOptionsHtml += `<option value="${scenario.id}" ${selected}>${scenario.scenario}</option>`;
            });
            scenarioOptionsHtml += `</optgroup>`;
        }

        showModal('Settings', `
            <p>Adjust application settings here.</p>
            <label style="display: flex; align-items: center; gap: 0.5rem;">
                API Key:
                <input type="password" id="settingApiKey" value="${API_KEY}" placeholder="Enter your API Key">
                <a href="https://aistudio.google.com/app/apikey" target="_blank" title="Manage your Google AI Studio API Keys" style="color: var(--accent-color); text-decoration: none;">üîó</a>
            </label>
            <label>
                Enable Quality Scoring:
                <input type="checkbox" id="settingEnableQuality" checked>
            </label>
            <label>
                Speech Volume:
                <input type="range" id="settingSpeechVolume" min="0" max="1" step="0.1" value="${speechService.volume}">
                <span id="speechVolumeValue">${speechService.volume}</span>
            </label>
            <label>
                Auto-Send Delay (seconds):
                <input type="number" id="settingAutoSendDelay" min="1" max="10" step="0.5" value="${autoSendDelay / 1000}">
            </label>
            <label>
                Call Scenario:
                <select id="settingCallScenario">
                    ${scenarioOptionsHtml}
                </select>
                <p style="font-size: 0.8em; color: var(--text-secondary); margin-top: 0.5rem;">Note: Voice quality depends on your browser's installed voices.</p>
            </label>
        `, () => {
            // Save settings logic
            speechService.setVolume(parseFloat(document.getElementById('settingSpeechVolume').value));
            autoSendDelay = parseFloat(document.getElementById('settingAutoSendDelay').value) * 1000; // Convert to milliseconds
            
            const selectedScenarioId = document.getElementById('settingCallScenario').value;
            // Find the selected scenario object
            let selectedScenario = null;
            for (const category in window.complaints) {
                selectedScenario = window.complaints[category].find(s => s.id === selectedScenarioId);
                if (selectedScenario) break;
            }
            currentScenario = selectedScenario;
            currentInitialCustomerScenarioText = currentScenario ? currentScenario.initialComplaint : "Hello, how can I help you today?";


            console.log('Settings saved:', { speechVolume: speechService.volume, autoSendDelay, currentScenario });
            hideModal();
            startNewRolePlay(); // Restart role play with new scenario
        });

        // Update volume display dynamically
        const speechVolumeSlider = document.getElementById('settingSpeechVolume');
        const speechVolumeValueSpan = document.getElementById('speechVolumeValue');
        speechVolumeSlider.oninput = () => {
            speechVolumeValueSpan.textContent = speechVolumeSlider.value;
        };
    });

    document.getElementById('open-persona').addEventListener('click', () => {
        showModal('Persona Selection', `
            <p>Choose or customize AI personas for role-play.</p>
            <label>
                Customer Persona:
                <textarea id="personaCustomer" rows="4" placeholder="Describe the customer persona">${customerPersona}</textarea>
            </label>
            <label>
                Quality Assistant Persona:
                <textarea id="personaQuality" rows="4" placeholder="Describe the quality assistant persona">${qualityAssistantPersona}</textarea>
            </label>
            <label>
                Flow Manager Persona:
                <textarea id="personaFlowManager" rows="4" placeholder="Describe the flow manager persona">${flowManagerPersona}</textarea>
            </label>
        `, () => {
            // Save persona logic
            customerPersona = document.getElementById('personaCustomer').value;
            qualityAssistantPersona = document.getElementById('personaQuality').value;
            flowManagerPersona = document.getElementById('personaFlowManager').value;
            console.log('Personas saved:', { customerPersona, qualityAssistantPersona, flowManagerPersona });
            hideModal();
        });
    });

    // --- Save Call Button Logic ---
    saveCallBtn.addEventListener('click', () => {
        if (!window.firebaseDb || !window.getUserId()) {
            showModal('Save Error', '<p>Firebase is not initialized or user not authenticated. Cannot save call. Please ensure you are connected to the internet and refresh the page.</p>', null);
            return;
        }

        showModal('Save Call', `
            <label>
                Call Name:
                <input type="text" id="callNameInput" placeholder="e.g., Billing Inquiry Practice 1">
            </label>
        `, async () => {
            const callName = document.getElementById('callNameInput').value.trim();
            if (!callName) {
                showModal('Save Error', '<p>Please enter a name for the call.</p>', null);
                return;
            }

            try {
                const db = window.firebaseDb;
                const userId = window.getUserId();
                const appId = typeof __app_id !== 'undefined' ? __app_id : 'default-app-id';

                // Path for private user data
                const callsCollectionRef = collection(db, `artifacts/${appId}/users/${userId}/calls`);

                const callData = {
                    callName: callName,
                    timestamp: firebase.firestore.FieldValue.serverTimestamp(), // Use server timestamp
                    chatHistory: chatHistory,
                    qualityFeedback: qualityFeedbackHistory,
                    scenario: currentScenario ? currentScenario.id : 'random_scenario', // Save scenario ID
                    userId: userId
                };

                await addDoc(callsCollectionRef, callData);
                console.log("Call saved successfully!");
                showModal('Success', `<p>Call "${callName}" saved successfully!</p>`, null);
            } catch (e) {
                console.error("Error saving call:", e);
                showModal('Error', `<p>Failed to save call: ${e.message}</p>`, null);
            }
        });
    });
    // --- End Save Call Button Logic ---

    // --- S4 Progress Indicator Logic ---
    function updateS4Progress(phase) {
        // Reset all phases first
        for (const key in s4Phases) {
            s4Phases[key].classList.remove('active', 'completed');
        }

        let foundActive = false;
        for (const key of ['S1', 'S2', 'S3', 'S4']) { // Ensure correct order
            if (key === phase) {
                s4Phases[key].classList.add('active');
                foundActive = true;
            } else if (!foundActive) {
                // This condition means 'key' is a phase *before* the current 'phase'
                s4Phases[key].classList.add('completed');
            }
            // If foundActive is true, and key is not 'phase', then it's a future phase, so leave it default (grey)
        }
    }

    // Function to start a new role-play session
    function startNewRolePlay() {
        chatHistory = []; // Clear history
        qualityFeedbackHistory = []; // Clear quality feedback history
        chat.querySelector('.messages').innerHTML = ''; // Clear chat display
        qualityFeedbackPanel.innerHTML = '<div class="quality-comment">Feedback will appear here after each of your responses.</div>';
        updateStatus('Start your call by speaking into the microphone.');
        currentS4Phase = 'S1'; // Reset S4 phase
        updateS4Progress(currentS4Phase); // Reset S4 progress to S1

        // Add a prominent initial message about microphone permissions
        addMessage("Welcome! To use the simulator, please ensure your browser has microphone access enabled. If you encounter issues, check your browser's site settings for microphone permissions and refresh the page.", 'ai', 'System:');

        // Flatten all scenarios into a single array for random selection
        const allScenarios = [];
        for (const category in window.complaints) {
            if (window.complaints && typeof window.complaints === 'object' && window.complaints[category]) {
                window.complaints[category].forEach(scenario => {
                    allScenarios.push(scenario);
                });
            }
        }
        
        // Randomly select a new scenario, different from the previous one if possible
        let newScenario = null;
        if (allScenarios.length > 1) {
            do {
                const randomIndex = Math.floor(Math.random() * allScenarios.length);
                newScenario = allScenarios[randomIndex];
            } while (newScenario === currentScenario); // Keep shuffling if it's the same as last time
        } else if (allScenarios.length === 1) {
            newScenario = allScenarios[0];
        } else {
            newScenario = { id: 'default', scenario: 'Default Scenario', initialComplaint: "Hello, how can I help you today?", customerName: "Customer", customerGender: "neutral" };
        }
        currentScenario = newScenario;
        currentInitialCustomerScenarioText = currentScenario.initialComplaint;

        // The customer does NOT start the call. The agent (user) starts.
        // The customer's initial complaint will be the *context* for the agent's first response.
        // We will add a system message to set the scene.
        addMessage(`Scenario: ${currentScenario.scenario}. The customer is ${currentScenario.customerName} and their initial complaint is: "${currentInitialCustomerScenarioText}". Please begin the call.`, 'ai', 'System:');
        
        // No initial customer message pushed to chatHistory here. The first user message will be the agent's greeting.
        // The first customer message will be generated by the AI after the agent's first turn.
    }

    // Initial setup when the page loads
    document.addEventListener('DOMContentLoaded', () => {
        // Ensure Firebase is initialized before proceeding with app logic that depends on it
        const checkFirebaseReady = setInterval(() => {
            if (window.firebaseDb && window.getUserId() !== 'anonymous') {
                clearInterval(checkFirebaseReady);
                console.log("Firebase is ready. User ID:", window.getUserId());
                startNewRolePlay();
            } else if (window.firebaseDb && window.getUserId() === 'anonymous' && typeof __initial_auth_token === 'undefined') {
                clearInterval(checkFirebaseReady);
                console.log("Firebase ready with anonymous user ID:", window.getUserId());
                startNewRolePlay();
            } else if (!window.firebaseConfig) {
                clearInterval(checkFirebaseReady);
                console.warn("Firebase config not found. Proceeding without call saving.");
                startNewRolePlay();
            }
        }, 100);
    });
  </script>
</body>
</html>
